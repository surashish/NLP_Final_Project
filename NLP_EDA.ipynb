{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpu55MqWu_7o"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import io\n",
    "#!pip install -U -q PyDrive\n",
    "import os\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yiQCTh-ycRiA"
   },
   "source": [
    "**Working import of a sample xml file from colab/drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T7tyORUTyJTf",
    "outputId": "881ccf3e-6fe6-4150-aed8-427fe6739c1f"
   },
   "outputs": [],
   "source": [
    "# ##Note: if you are updating a file, re-run this cell to update the image of drive\n",
    "\n",
    "# # 1. Authenticate and create the PyDrive client.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "# # 2.  mount the google drive into colab. Now you can use terminal commmands like\n",
    "# #     !ls, !pwd, etc to navigate to your files. You should get a message like \n",
    "# #     'Drive already mounted' or, it will ask you to authenticate with google.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/', force_remount=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21eCrL0sdipH"
   },
   "source": [
    " **Importing annotation file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIMfD2xUreWj"
   },
   "source": [
    "**Extracting top and bottom text annotation, and separate the XML **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'PowerAnnotations_V1.0/AnnotatedThreads/non train/'\n",
    "\n",
    "#run this for train in case you need it\n",
    "#mypath = 'PowerAnnotations_V1.0/AnnotatedThreads/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "Op-G0m9ZxL6I",
    "outputId": "65fd804c-a40a-41d0-f0d3-7387334eac17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thread99.MN.infoadded.xml',\n",
       " 'thread104.MN.infoadded.xml',\n",
       " 'thread86.MN.infoadded.xml',\n",
       " 'thread92.MN.infoadded.xml',\n",
       " 'thread89.MN.infoadded.xml',\n",
       " 'thread96.MN.infoadded.xml',\n",
       " 'thread100.MN.infoadded.xml',\n",
       " 'thread82.MN.infoadded.xml',\n",
       " 'thread105.MN.infoadded.xml',\n",
       " 'thread98.MN.infoadded.xml',\n",
       " 'thread93.MN.infoadded.xml',\n",
       " 'thread88.MN.infoadded.xml',\n",
       " 'thread65.MN.infoadded.xml',\n",
       " 'thread83.MN.infoadded.xml',\n",
       " 'thread101.MN.infoadded.xml',\n",
       " 'thread90.MN.infoadded.xml',\n",
       " 'thread84.MN.infoadded.xml',\n",
       " 'thread106.MN.infoadded.xml',\n",
       " 'thread66.MN.infoadded.xml',\n",
       " 'thread102.MN.infoadded.xml',\n",
       " 'thread94.MN.infoadded.xml',\n",
       " 'thread72.MN.infoadded.xml',\n",
       " 'thread109.MN.infoadded.xml',\n",
       " 'thread91.MN.infoadded.xml',\n",
       " 'thread68.MN.infoadded.xml',\n",
       " 'thread85.MN.infoadded.xml',\n",
       " 'thread103.MN.infoadded.xml',\n",
       " 'thread81.MN.infoadded.xml',\n",
       " 'thread67.MN.infoadded.xml',\n",
       " 'thread108.MN.infoadded.xml',\n",
       " 'thread95.MN.infoadded.xml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all files in folder.\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "filesInDir = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f[-4:] == '.xml')]\n",
    "filesInDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yym3Qwx85fiA"
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i, f in enumerate(filesInDir):\n",
    "    file = open(mypath + f, 'r' , encoding=\"ISO-8859-1\")\n",
    "    data[f] = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFile(name, data):\n",
    "    fw = open(name, \"w+\")\n",
    "    fw.write(data)\n",
    "    fw.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqSC10mKh-9U"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b48c883654b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mseparatedXML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<custom>(.|\\n)*?<\\/custom>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# --- run this line below for train data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mseparatedXML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<xml>(.|\\n)*?<\\/xml>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcolumnOfXML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseparatedXML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "#read each file in directory, then extract top & bottom annotations, amd XML. \n",
    "# Write xml to a separate dir.\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "save_path = '/Users/t_sura/Desktop/School/NLP/project/NLP_Final_Project/Clean XML files'\n",
    "\n",
    "#name_of_file = raw_input(\"What is the name of the file: \")\n",
    "\n",
    "#\n",
    "df = pd.DataFrame(columns = ['filename', 'top_annotation', 'bottom_annotation'])\n",
    "  \n",
    "rownum = 0\n",
    "topAnno = []\n",
    "bottomAnno = []\n",
    "xmlfilename = []\n",
    "columnOfXML = []\n",
    "for k, v in data.items():\n",
    "    searchObj = re.search('<custom>(.|\\n)*?<\\/custom>', v)\n",
    "    #searchObj = re.search('<xml>(.|\\n)*?<\\/xml>', v)\n",
    "    separatedXML = re.search('<custom>(.|\\n)*?<\\/custom>', v).group(0)\n",
    "    # --- run this line below for train data ---\n",
    "    separatedXML = re.search('<xml>(.|\\n)*?<\\/xml>', v).group(0)\n",
    "    # ---\n",
    "    columnOfXML.append(separatedXML)\n",
    "    (startOfXML, endOfXML) = searchObj.span()\n",
    "    topAnno.append(v[:startOfXML])\n",
    "    bottomAnno.append(v[endOfXML:])\n",
    "    xmlfilename.append('clean_xml_' + k)\n",
    "    \n",
    "    name = 'clean_xml_' + k\n",
    "    completeName = os.path.join(save_path, name)  \n",
    "    writeFile(completeName, separatedXML)\n",
    "\n",
    "df['filename'] = pd.Series(xmlfilename)\n",
    "df['top_annotation'] = pd.Series(topAnno)\n",
    "df['bottom_annotation'] = pd.Series(bottomAnno)\n",
    "df['XML'] = pd.Series(columnOfXML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1010
    },
    "colab_type": "code",
    "id": "xyBNx2Nfn4cR",
    "outputId": "c0eaf51a-5d74-447a-be29-a98eb804d8a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>top_annotation</th>\n",
       "      <th>bottom_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, top_annotation, bottom_annotation]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.to_csv('separat\\ed_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "colab_type": "code",
    "id": "GywrYq3vpNqd",
    "outputId": "201a22da-20a9-4044-b814-25d26a45383c"
   },
   "outputs": [],
   "source": [
    "#df.to_csv('separated_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3rWUPsfOK0C"
   },
   "source": [
    "### Cleaning data further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. MTags for example M3.6. and M3.10\n",
    "##### 2. Removed [....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_message(data):\n",
    "    \n",
    "    #parser1 = ET.XMLParser(encoding=\"ISO-8859-1\")\n",
    "    tree = ET.ElementTree(ET.fromstring(data))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    message = []\n",
    "    for each in root.iter(tag='row'):\n",
    "        message.append(each)\n",
    "    \n",
    "    text_message = []\n",
    "    \n",
    "    for each in message:\n",
    "        text_message.append(ET.tostring(each))\n",
    "    #print(text_message)\n",
    "    return text_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "not well-formed (invalid token): line 158, column 25 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/t_sura/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2963\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-45-89a7af7b80a3>\"\u001b[0m, line \u001b[1;32m23\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    extract_message(data)\n",
      "  File \u001b[1;32m\"<ipython-input-44-9df96f9ce52d>\"\u001b[0m, line \u001b[1;32m4\u001b[0m, in \u001b[1;35mextract_message\u001b[0m\n    tree = ET.ElementTree(ET.fromstring(data))\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/t_sura/anaconda3/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m1314\u001b[0;36m, in \u001b[0;35mXML\u001b[0;36m\u001b[0m\n\u001b[0;31m    parser.feed(text)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m not well-formed (invalid token): line 158, column 25\n"
     ]
    }
   ],
   "source": [
    "path = \"Clean XML files/\"\n",
    "name = 'clean_xml_thread98.MN.infoadded.xml'\n",
    "f = open(path  + name)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "\n",
    "def removeMTagsAndBracketComments(data):\n",
    "# removing mtags\n",
    "    sansMTags1 = re.sub('M[\\d]?\\.[\\d]+\\.', '' , data)\n",
    "    sansMTags2 = re.sub('M[\\d]?\\.[\\d]+', '', sansMTags1)\n",
    "    sansBracketComments = re.sub('\\[.+\\]', '' , sansMTags2)\n",
    "    return sansBracketComments\n",
    "\n",
    "\n",
    "sansBracketComments = removeMTagsAndBracketComments(data)\n",
    "#write\n",
    "name = 'test_sansMtag2.txt'\n",
    "writeFile(name, sansBracketComments)\n",
    "\n",
    "#sansBracketComments\n",
    "\n",
    "extract_message(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sansMessageEndTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<content>\\n\\n Andy,\\n\\n\\n\\n\\n\\n Attached are some ideas for possible charge structures for EnronOnline.\\n\\n I am recommending something which will probably be surprising, given our conversation.\\n\\n Let's discuss when you have a moment.\\n\\n\\n\\n\\n\\n Dave\\n\\n\\n\\n\\n\\n\\n\\n Recommendation\\n\\n\\n\\n\\n\\n a) For new commodity areas, continue to charge a set up fee in accordance with our previously agreed schedule.\\n\\n (e.g. $350,000 for new Market Area)\\n\\n\\n\\nSflink1.8\\n\\n\\n\\n b) Charge a per-volume maintenance fee which is comparable to industry brokerage fees,\\n\\n with a minimum charge equivalent to $4,000 per Product * Total number of Products).\\n\\n\\n\\nSflink1.10\\n\\n\\n\\n This method results in a total charge of approx. $46.5 million pa.\\n\\n (providing coverage for existing charges, some growth and London's charges)\\n\\n\\n\\n\\n\\n This method is recommended because it balances a fee to reflect real expenditure of effort on behalf on Enron Online staff (the per Product minimum)\\n\\n with a structure which is recognizeable (and hopefully more easily sold) to the traders.\\n\\n\\n\\n\\n\\n This structure is primarily not cost-driven, but is value-driven;\\n\\n those who derive the greatest value pay the highest costs.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Example Charges\\n\\n\\n\\n\\n\\n Here are some example charges if we use the recommended method:\\n\\n\\n\\n\\n\\n Commodity\\t\\t\\tCharge\\n\\n\\n\\nUS Nat Gas\\t\\t\\t$24,282,875\\n\\nUS Power\\t\\t\\t$  5,163,563\\n\\nMetals\\t\\t\\t\\t$  5,798,144\\n\\nCrude &amp; Products\\t\\t$  3,578,560\\n\\nNorwegian Power\\t\\t$     380,869\\n\\nGlobal Credit\\t\\t\\t$     400,000\\n\\nCoal\\t\\t\\t\\t$     966,265\\n\\nBandwidth \\t\\t\\t$     312,000\\n\\n\\n\\n\\n\\n Or, by Group:\\n\\n\\n\\nENA\\t\\t$30,647,772\\n\\nEEL\\t\\t$  8,774,844\\n\\nEGM\\t\\t$  6,741,955\\n\\nEIM\\t\\t$     106,250\\n\\nEBS\\t\\t$     312,000\\n\\nTotal:\\t\\t$46,582,821\\n\\n\\n\\n\\n\\n Sensitivity\\n\\n\\n\\n\\n\\n With the recommended structure, if transactions for 2001 are:\\n\\n\\n\\n\\n\\n a) The same as the last half of 2000 * 2, then we recover approx. $46 million.\\n\\n\\n\\n\\n\\n b) Double, then we recover approx. $90 million\\n\\n\\n\\n\\n\\n c) Half, then we recover approx.$24 million\\n\\n\\n\\n\\n\\n c) Zero, then we recover approx. $6.4 million\\n\\n\\n\\n\\n\\n\\n\\n Alternatives - Basic Structure\\n\\n\\n\\n\\n\\n Any of the following could be combined to create additional alternatives:\\n\\n\\n\\n\\n\\n Alternative 1: As per the recommended structure, but charge a flat per-transaction fee instead of a per volume fee. This would result in a charge of $xx per transaction.\\n\\n\\n\\nSflink1.29\\n\\n\\n\\n Alternative 2: Charge by Product Types (we currently have 358, so full charge would be approx. $112,000 per Product Type)\\n\\n\\n\\n\\n\\n Alternative 3: Charge by Products (we currently have 1500 per day, so full charge would be approx. $27,000 per Product)\\n\\n\\n\\n\\n\\n Alternative 4: Charge by Country/Commodity (we currently have 61, so full charge would be approx. $656,000 per Country/Commodity)\\n\\n\\n\\n\\n\\n Alternative 5: Use the same methodology as currently used for the cost allocation (55% of cost allocation based on number of transactions and 45% based on Country/Commodity Markets Served) This would result in transaction charges of approx. xxx per transaction and $295,000 per Market served.\\n\\n\\n\\n\\n\\n\\n\\n Alternatives - Different Structures\\n\\n\\n\\n\\n\\n Alternative 5: Separate Marketing costs and charge directly to business units based on activity\\n\\n\\n\\n\\n\\n Alternative 6: Separate Development costs as a separate item not covered by the basic charge structure, but recovered solely through increases in EnronOnline business.\\n\\n\\n\\n\\n\\n</content>\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sObj = re.search('<content>(.|\\n)*?\\<\\/content>', sansBracketComments)\n",
    "sObj.group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting body of message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBodyOfMessage(sansBracketComments):\n",
    "    emailBodys = []\n",
    "    i = re.finditer('<content>(.|\\n)*?\\<\\/content>', sansBracketComments)\n",
    "    for each in i:\n",
    "        emailBodys.append(each.group(0))\n",
    "\n",
    "    body = ''\n",
    "    for text in emailBodys:\n",
    "        body = body + text\n",
    "\n",
    "\n",
    "    #removing the <tag>\n",
    "    body = re.sub('<content>', '' , body)\n",
    "    body = re.sub('</content>', '' , body)\n",
    "    body = re.sub('<custom>', '' , body)\n",
    "    body= re.sub('</custom>', '' , body)\n",
    "\n",
    "    body= re.sub('Sflink[\\d]+.[\\d]+', '' , body)\n",
    "    body= re.sub('Blink[\\d]+.[\\d]+', '' , body)\n",
    "    body= re.sub('Flink[\\d]+.[\\d]+', '' , body)\n",
    "\n",
    "    return body\n",
    "\n",
    "name = 'sampleBody.txt'\n",
    "writeFile(name, body)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Forster\n",
      "David Forster\n",
      "David Forster\n",
      "David Forster\n",
      "David Forster\n",
      "David Forster\n"
     ]
    }
   ],
   "source": [
    "#Fetching the 'from' tags\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.ElementTree(ET.fromstring(data))\n",
    "root = tree.getroot()\n",
    "\n",
    "for something in root.iter(tag='from'):\n",
    "    print(something.get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106860\n",
      "2000020\n",
      "106859\n",
      "2000021\n",
      "106858\n"
     ]
    }
   ],
   "source": [
    "for something in root.iter(tag='message_id'):\n",
    "    print(something.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'row' at 0x117aae728>,\n",
       " <Element 'row' at 0x117ad0548>,\n",
       " <Element 'row' at 0x117ad0868>,\n",
       " <Element 'row' at 0x117ad0cc8>,\n",
       " <Element 'row' at 0x117ad0f98>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP_EDA.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
